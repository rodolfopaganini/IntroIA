{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios de la primera clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejecicio #1:    Operaciones Matriciales\n",
    "Dada una matriz en formato numpy array, donde cada fila de la matriz representa un vector matemático: \n",
    "* Computar las normas l0, l1, l2, l-infinito\n",
    "    * l0: número de elementos diferentes a cero en el vector\n",
    "    * l1-l2: \n",
    "    ![](https://latex.codecogs.com/svg.latex?%7B%5Ccolor%7BOrange%7D%20%5Cleft%20%5C%7C%20x%20%5Cright%20%5C%7C_%7Bp%7D%20%3D%20%5Cleft%20%28%20%5Csum_%7B1%7D%5E%7Bn%7D%20%5Cleft%20%7C%20x_%7Bi%7D%20%5Cright%20%7C%5Ep%20%5Cright%20%29%5E%7B%5Ctfrac%7B1%7D%7Bp%7D%7D%7D)\n",
    "    * l-infinito:\n",
    "     ![](https://latex.codecogs.com/svg.latex?%7B%5Ccolor%7BOrange%7D%20%5Cleft%20%5C%7C%20x%20%5Cright%20%5C%7C_%7B%5Cinfty%7D%20%3D%20max_%7Bi%7D%20%5Cleft%20%7C%20x_%7Bi%7D%20%5Cright%20%7C%7D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_p(input, p):\n",
    "    \"\"\"\n",
    "    calculate and return the p-norm of a numpy matrix, row-wise. For p < 0 the infinite norm is used\n",
    "    :param input: 2-d matrix\n",
    "    :param p: norm order\n",
    "    :return: column vector with the p-norm of each row of the input matrix\n",
    "    \"\"\"\n",
    "\n",
    "    # Handle case of norm 0\n",
    "    if p == 0:\n",
    "        return np.count_nonzero(input, axis=1)\n",
    "\n",
    "    # Handle case of infinite norm\n",
    "    if p < 0:\n",
    "        return np.max(np.abs(input), axis=1)\n",
    "\n",
    "    # Handle the rest of the cases\n",
    "    return np.sum(input ** p, axis=1) ** (1 / p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm 0: expected: [3 3 2], obtained: [3 3 2]\n",
      "norm 1: expected: [6 15 15], obtained: [ 6. 15. 15.]\n",
      "norm 2: expected: [3.74  8.77 10.63], obtained: [ 3.74165739  8.77496439 10.63014581]\n",
      "norm infinite: expected: [3 6 8], obtained: [3 6 8]\n"
     ]
    }
   ],
   "source": [
    "# Test the function norm_p\n",
    "matrix = np.array([[1, 2, 3], [4, 5, 6], [0, 7, 8]])\n",
    "\n",
    "print('norm 0: expected: [3 3 2], obtained:', norm_p(matrix, 0))\n",
    "print('norm 1: expected: [6 15 15], obtained:', norm_p(matrix, 1))\n",
    "print('norm 2: expected: [3.74  8.77 10.63], obtained:', norm_p(matrix, 2))\n",
    "print('norm infinite: expected: [3 6 8], obtained:', norm_p(matrix, -1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejecicio #2:    Sorting\n",
    "Dada una matriz en formato numpy array, donde cada fila de la matriz representa un vector matemático, se requiere computar la norma l2 de cada vector.\n",
    "Una vez obtenida la norma, se debe ordenar las mísmas de mayor a menor. Finalmente, obtener la matriz original ordenada por fila según la norma l2.\n",
    "\n",
    "_Todas las operaciones debe ser vectorizadas._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorting(input):\n",
    "    \"\"\"\n",
    "    Given a 2-d numpy array, calculate 2-norm of each row, then sort them and\n",
    "    finally return the original array with its rows sorted the rows in the\n",
    "    order of the 2-norm\n",
    "\n",
    "    :param input: 2-d numpy array\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # Apply the norm to all rows\n",
    "    norms = norm_p(input, 2)\n",
    "\n",
    "    # Get the indexes of the sorted norms\n",
    "    sorted_indexes = np.argsort(norms)\n",
    "\n",
    "    # Apply those indexes to the input matrix and return\n",
    "    return input[sorted_indexes, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected: [[0 1 2], [3 4 5], [6 7 8]], obtained: [[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n"
     ]
    }
   ],
   "source": [
    "# Test the function sorting\n",
    "matrix = np.array([[3, 4, 5], [0, 1, 2], [6, 7, 8]])\n",
    "print('expected: [[0 1 2], [3 4 5], [6 7 8]], obtained:', sorting(matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejecicio #3:    Indexing\n",
    "El objetivo es construir un índice para identificadores de usuarios, es decir _id2idx_ e _idx2id_.\n",
    "Para ello crear una clase, donde el índice se genere en el constructor. Armar métodos _get_users_id_ y _get_users_idx_.\n",
    "\n",
    "* Identificadores de usuarios : users_id = [15, 12, 14, 10, 1, 2, 1]\n",
    "* Índice de usuarios : users_id = [0, 1, 2, 3, 4, 5, 4]\n",
    "\n",
    "```\n",
    "id2idx =  [-1     4     5    -1    -1    -1     -1    -1    -1    -1     3     -1      1    -1     2     0]\n",
    "          [ 0     1     2     3     4     5      6     7     8     9    10     11     12    13    14    15]\n",
    "\n",
    "id2idx[15] -> 0 ; id2idx[12] -> 1 ; id2idx[3] -> -1\n",
    "idx2id[0] -> 15 ; idx2id[4] -> 1\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Indexing():\n",
    "    def __init__(self, ids):\n",
    "        self._ids = ids\n",
    "\n",
    "    def get_users_id(self, idx):\n",
    "        # Return -1 if the index is out of range\n",
    "        if idx < len(self._ids):\n",
    "            return self._ids[idx]\n",
    "        return -1\n",
    "\n",
    "    def get_users_idx(self, id):\n",
    "        # Return -1 if there's no user with the given ID\n",
    "        location = np.where(self._ids == id)[0]\n",
    "        if len(location) > 0:\n",
    "            return location[0]\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected: 0, obtained: 0\n",
      "expected: 1, obtained: 1\n",
      "expected: -1, obtained: -1\n",
      "expected: 15, obtained: 15\n",
      "expected: 1, obtained: 1\n"
     ]
    }
   ],
   "source": [
    "# Test the indexing class\n",
    "indexing_obj = Indexing(np.array([15, 12, 14, 10, 1, 2]))\n",
    "print('expected: 0, obtained:', indexing_obj.get_users_idx(15))\n",
    "print('expected: 1, obtained:', indexing_obj.get_users_idx(12))\n",
    "print('expected: -1, obtained:', indexing_obj.get_users_idx(3))\n",
    "print('expected: 15, obtained:', indexing_obj.get_users_id(0))\n",
    "print('expected: 1, obtained:', indexing_obj.get_users_id(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejecicio #4:    Precision, Recall, Accuracy\n",
    "En los problemas de clasificación, se cuenta con dos arreglos, la **verdad** (ground truth) y la **predicción** (prediction). \n",
    "Cada elemento de los arreglos puede tomar dos valores: _True_ (representado por 1) y _False_ (representado por 0). \n",
    "Por lo tanto, se pueden definir cuatro variables:\n",
    "* True Positive (TP): la verdad es 1 y la predicción es 1.\n",
    "* True Negative (TN): la verdad es 0 y la predicción es 0.\n",
    "* False Negative (FN): la verdad es 1 y la predicción es 0.\n",
    "* False Positive (FP): la verdad es 0 y la predicción es 1.\n",
    "\n",
    "A partir de esas cuatro variables, se definen las siguientes métricas:\n",
    "* Precision = TP / (TP + FP)\n",
    "* Recall = TP / (TP + FN)\n",
    "* Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "Para los siguientes arreglos, representando la **verdad** y la **predicción**,\n",
    "calcular las métricas anteriores con operaciones vectorizadas en NumPy.\n",
    "* truth = [1,1,0,1,1,1,0,0,0,1]\n",
    "* prediction = [1,1,1,1,0,0,1,1,0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_accuracy(truth, prediction):\n",
    "    \"\"\"\n",
    "    This function retrieves precision, recall and accuracy, calculated for the input arrays\n",
    "    :param truth:\n",
    "    :param prediction:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate true positive, true negative, false positive and false negatice\n",
    "    tp = np.sum(truth * prediction)\n",
    "    fp = np.sum(np.logical_not(truth) * prediction)\n",
    "    tn = np.sum(np.logical_not(truth) * np.logical_not(prediction))\n",
    "    fn = np.sum(truth * np.logical_not(prediction))\n",
    "\n",
    "    # Calculate the precision, recall and accuracy\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "    # Return all calculated values\n",
    "    return precision, recall, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5, 0.5, 0.4)\n"
     ]
    }
   ],
   "source": [
    "# Test the function precision_recall_accuracy\n",
    "print(precision_recall_accuracy(np.array([1,1,0,1,1,1,0,0,0,1]), np.array([1,1,1,1,0,0,1,1,0,0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejecicio #5:    Average Query Precision\n",
    "En information retrieval o search engines, en general contamos con queries “q” y para cada “q” una lista de documentos que son verdaderamente relevantes. \n",
    "Para evaluar un search engine, es común utilizar la métrica **average query precision**.\n",
    "Tomando de referencia el siguiente ejemplo, calcular la métrica con NumPy utilizando operaciones vectorizadas.\n",
    "```\n",
    "q_id =             [1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4]\n",
    "predicted_rank =   [0, 1, 2, 3, 0, 1, 2, 0, 1, 2, 3, 4, 0, 1, 2, 3]\n",
    "truth_relevance =  [T, F, T, F, T, T, T, F, F, F, F, F, T, F, F, T] \n",
    "```\n",
    "* Precision para q_id 1 = 2 / 4\n",
    "* Precision para q_id 2 = 3 / 3\n",
    "* Precision para q_id 3 = 0 / 5\n",
    "* Precision para q_id 4 = 2 / 4\n",
    "\n",
    "**_average query precision_** = ((2/4) + (3/3) + (0/5) + (2/4)) / 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_query_precision(q_id, predicted_rank, truth_relevance):\n",
    "    # Get the precision for each of the unique values of q_id\n",
    "    unique = np.unique(q_id)\n",
    "    precisions = np.empty(len(unique))\n",
    "    for i, value in enumerate(unique):\n",
    "        mask = q_id == value\n",
    "        n_values = np.sum(mask)\n",
    "        n_true = np.sum(mask * truth_relevance)\n",
    "        precisions[i] = n_true / n_values\n",
    "\n",
    "    # Return the average of the precisions\n",
    "    return np.average(precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected: 0.5, obtained: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Test the function average_query_precision\n",
    "q_id = np.array([1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4])\n",
    "predicted_rank = np.array([0, 1, 2, 3, 0, 1, 2, 0, 1, 2, 3, 4, 0, 1, 2, 3])\n",
    "truth_relevance = np.array([1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1])\n",
    "print('expected: 0.5, obtained:', average_query_precision(q_id, predicted_rank, truth_relevance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejecicio #6:    Distancia a Centroides\n",
    "Dada una nube de puntos _X_ y centroides _C_, obtener la distancia entre\n",
    "cada vector _X_ y los centroides utilizando operaciones vectorizadas y broadcasting en NumPy.\n",
    "Utilizar como referencia los siguientes valores:\n",
    "```\n",
    "X = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "C = [[1, 0, 0], [0, 1, 1]]   \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroids_distance(points, centroids):\n",
    "    \"\"\"\n",
    "    Calculates the distance between each point to each centroid. All\n",
    "    elements are (1, 3) and the returned array is (len(points), len(centroids))\n",
    "    :param points:\n",
    "    :param centroids:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # The idea is to convert the points into an array (1, n_points * points.shape[1])\n",
    "    # and then to subtract the centers. I should get (n_centers, n_points * points.shape[1])\n",
    "    points_flat = points.reshape(1, points.shape[0] * points.shape[1])\n",
    "    subtraction = points_flat - np.tile(centroids, (1, points.shape[0]))\n",
    "    column = np.reshape(subtraction ** 2, (len(centroids) * points.shape[0], points.shape[1]))\n",
    "    squares_sum = np.sum(column, axis=1)\n",
    "\n",
    "    return np.reshape(np.sqrt(squares_sum), (len(centroids), len(points)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected: [[0.707 1.5 13.45], [1.22  0.5  12.73]], obtained: [[ 0.70710678  1.5        13.45362405]\n",
      " [ 1.22474487  0.5        12.72792206]]\n"
     ]
    }
   ],
   "source": [
    "# Test function centroids_distance\n",
    "points = np.array([[1, 0.5, 0.5], [0.5, 1, 1], [7, 8, 9]])\n",
    "centroids = np.array([[1, 0, 0], [0, 1, 1]])\n",
    "print('expected: [[0.707 1.5 13.45], [1.22  0.5  12.73]], obtained:', centroids_distance(points, centroids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejecicio #7:    Etiquetar Cluster\n",
    "Obtener para cada fila en _X_, el índice de la fila en _C_ con distancia euclídea más pequeña. \n",
    "Es decir, para cada fila en _X_, determinar a qué cluster pertenece en C.\n",
    "\n",
    "\n",
    "_Hint_: usar np.argmin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_tag(points, centroids):\n",
    "    \"\"\"\n",
    "    Calculates which is the closest centroid to each point\n",
    "    :param points:\n",
    "    :param centroids:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    return np.argmin(centroids_distance(points, centroids), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected: [0 1 1], obtained: [0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Test function cluster_tag\n",
    "print('expected: [0 1 1], obtained:', cluster_tag(points, centroids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio #8:   Implementación Básica de K-means\n",
    "K-means es uno de los algoritmos más básicos en Machine Learning no supervisado.\n",
    "Es un algoritmo de clusterización, que agrupa datos que comparten características similares.\n",
    "Recordemos que entendemos datos como _n_ realizaciones del vector aleatorio _X_.\n",
    "\n",
    "El algoritmo funciona de la siguiente manera:\n",
    "1. El usuario selecciona la cantidad de clusters a crear _n_.\n",
    "2. Se seleccionan _n_ elementos aleatorios de _X_ como posiciones iniciales del los centroides _C_.\n",
    "3. Se calcula la distancia entre todos los puntos en _X_ y todos los puntos en _C_.\n",
    "4. Para cada punto en _X_ se selecciona el centroide más cercano de _C_.\n",
    "5. Se recalculan los centroides _C_ a partir de usar las filas de _X_ que pertenecen a cada centroide. \n",
    "6. Se itera entre 3 y 5 una cantidad fija de veces o hasta que la posición de los centroides no cambie dada una tolerancia.\n",
    "\n",
    "Se debe por lo tanto implementar la función k_means(X, n) de manera tal que, al finalizar, devuelva la posición de los centroides\n",
    "y a qué cluster pertenece cada fila de _X_. \n",
    "\n",
    "_Hint_: para (2) utilizar funciones de np.random, para (3) y (4) usar los ejercicios anteriores, \n",
    "para (5) es válido utilizar un for. Iterar 10 veces entre (3) y (5).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(data, n, max_iter, tol=1e-3):\n",
    "    \"\"\"\n",
    "    k-means implementation\n",
    "    :param data: data to be classified\n",
    "    :param n: amount of clusters\n",
    "    :param max_iter: maximum amount of iterations\n",
    "    :param tol: the tolerance used for the centroids displacements:\n",
    "        if the centroids move less than the tolerance, return them\n",
    "    :return:\n",
    "        - centroids\n",
    "        - membership table\n",
    "    \"\"\"\n",
    "    \n",
    "    # Take n random elements from the data\n",
    "    indexes = np.random.choice(data.shape[0], n, replace=False)\n",
    "    centroids = data[indexes]\n",
    "    \n",
    "    # Initialize the membership table for the initial values\n",
    "    membership = cluster_tag(data, centroids)\n",
    "    # Iterate until the maximum amount is reached\n",
    "    for i in range(max_iter):\n",
    "        # Iterate over al the clusters and update their centroids\n",
    "        total_displacement = 0\n",
    "        for j in range(n):\n",
    "            # Calculate the new centroid for the cluster\n",
    "            mask = membership == j\n",
    "            points_included = data[mask]\n",
    "            new_centroid = np.average(points_included, axis=0)\n",
    "            \n",
    "            # Calculate the displacement between the old and the new centroid and add it to the total displacement\n",
    "            displacement = centroids_distance(\n",
    "                centroids[j].reshape((1, len(new_centroid))),\n",
    "                new_centroid.reshape((1, len(new_centroid))),\n",
    "            )[0]\n",
    "            total_displacement += abs(displacement)\n",
    "            \n",
    "            # Update the centroid\n",
    "            centroids[j] = new_centroid\n",
    "            \n",
    "        # Update the distribution of the data considering the new centroids\n",
    "        membership = cluster_tag(data, centroids)\n",
    "    \n",
    "        # If the total displacement was below the tolerance, return\n",
    "        if total_displacement < tol:\n",
    "            break\n",
    "    \n",
    "    # Return the found centroids and the membershuip table\n",
    "    return centroids, membership\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centroids:  [[ 1.21516465 -0.17271159  0.01284632 -0.01393214]\n",
      " [-0.2186828   1.18785086 -0.01274398  0.0238751 ]]\n",
      "precision: 0.23803036980648262\n",
      "recall: 0.23764\n",
      "accuracy: 0.23846\n"
     ]
    }
   ],
   "source": [
    "# Test kmeans\n",
    "\n",
    "# Generate a dataset\n",
    "k = 1  # Distance modulator\n",
    "n = 100000  # Samples number\n",
    "data = k * np.array([[1, 0, 0, 0], [0, 1, 0, 0]])\n",
    "data = np.repeat(data, n / 2, axis=0)\n",
    "data = data + np.random.normal(0, 1, data.shape)\n",
    "\n",
    "# True membership table A: A=1, B=0\n",
    "index = np.array([[1], [0]])\n",
    "index = np.repeat(index, n / 2, axis=0)\n",
    "\n",
    "# Call kmeans\n",
    "centroids, membership = kmeans(data, 2, 10)\n",
    "print('centroids: ', centroids)\n",
    "precision, recall, accuracy = precision_recall_accuracy(index.T[0], membership)\n",
    "print('precision:', precision)\n",
    "print('recall:', recall)\n",
    "print('accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "\n",
    "The values obtained for precision, recall and accuracy could be around 0.76 or 0.24, depending on if the clusters\n",
    "were found in the same order they were defined or in the opposite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio #9:   Computar Métricas con \\_\\_call__\n",
    "En problemas de machine learning, es muy común que para cada predicción que obtenemos en nuestro dataset de verificacion y evaluacion, almacenemos en arreglos de numpy el resultado de dicha predicción, junto con el valor verdadero y parámetros auxiliares (como el ranking de la predicción y el query id). \n",
    "\n",
    "Luego de obtener todas las predicciones, podemos utilizar la información almacenada en los arreglos de numpy, para calcular todas las métricas que queremos medir en nuestro sistema. \n",
    "\n",
    "Una buena práctica para implementar esto en Python, es crear clases que hereden de una clase Metric “base” y que cada métrica implemente el método \\_\\_call__.\n",
    "\n",
    "Utilizar herencia, operador \\_\\_call__ y _kwargs_, para escribir un programa que permita calcular todas las métricas de los ejercicios anteriores mediante un for.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric():\n",
    "    \"\"\"\n",
    "    This is the base class for all the metrics.\n",
    "    The keys 'truth' and 'predictions' are required in the kwargs.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Class constructor\n",
    "        \"\"\"\n",
    "        \n",
    "        # Define a private member which will be True if there's any issue with the input\n",
    "        self._error = False\n",
    "        \n",
    "        # Store the truth in a private member\n",
    "        # TODO it would be better to raise errors when the required keys aren't present\n",
    "        if 'truth' not in kwargs:\n",
    "            print('The key `truth` is missing from the kwargs.')\n",
    "            self._error = True\n",
    "        else:\n",
    "            self._truth = kwargs.pop('truth')\n",
    "            \n",
    "        # Store the predictions in a private member\n",
    "        # TODO it would be better to raise errors when the required keys aren't present\n",
    "        if 'predictions' not in kwargs:\n",
    "            print('The key `predictions` is missing from the kwargs.')\n",
    "            self._error = True\n",
    "        else:\n",
    "            self._predictions = kwargs.pop('predictions')\n",
    "\n",
    "        # Check that truth and predictions have the same shape\n",
    "        if self._truth.shape != self._predictions.shape:\n",
    "            print('The shape of truth ({}) and the one of the predictions ({}) differ'.format(\n",
    "                self._truth.shape,\n",
    "                self._predictions.shape,\n",
    "            ))\n",
    "            self._error = True\n",
    "            \n",
    "        # Store the rest of the kwargs in a separate private member\n",
    "        self._additionals = kwargs\n",
    "        \n",
    "        \n",
    "class Precision(Metric):\n",
    "    \"\"\"\n",
    "    Class for obtaining the precision\n",
    "    \"\"\"\n",
    "    \n",
    "    def __call__(self):\n",
    "        \"\"\"\n",
    "        This method calculates and returns the precision\n",
    "        \"\"\"\n",
    "\n",
    "        # If there was any issue with the input parameters, return None\n",
    "        if self._error is True:\n",
    "            return None\n",
    "        \n",
    "        # Calculate and return the precision\n",
    "        tp = np.sum(self._truth * self._predictions)\n",
    "        fp = np.sum(np.logical_not(self._truth) * self._predictions)\n",
    "        return tp / (tp + fp)\n",
    "\n",
    "\n",
    "class Recall(Metric):\n",
    "    \"\"\"\n",
    "    Class for obtaining the recall\n",
    "    \"\"\"\n",
    "    \n",
    "    def __call__(self):\n",
    "        \"\"\"\n",
    "        This method calculates and returns the recall\n",
    "        \"\"\"\n",
    "\n",
    "        # If there was any issue with the input parameters, return None\n",
    "        if self._error is True:\n",
    "            return None\n",
    "        \n",
    "        # Calculate and return the precision\n",
    "        tp = np.sum(self._truth * self._predictions)\n",
    "        fn = np.sum(self._truth * np.logical_not(self._predictions))\n",
    "        return tp / (tp + fn)\n",
    "    \n",
    "    \n",
    "class Accuracy(Metric):\n",
    "    \"\"\"\n",
    "    Class for obtaining the accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    def __call__(self):\n",
    "        \"\"\"\n",
    "        This method calculates and returns the accuracy\n",
    "        \"\"\"\n",
    "\n",
    "        # If there was any issue with the input parameters, return None\n",
    "        if self._error is True:\n",
    "            return None\n",
    "        \n",
    "        # Calculate and return the accuracy\n",
    "        tp = np.sum(self._truth * self._predictions)\n",
    "        tn = np.sum(np.logical_not(self._truth) * np.logical_not(self._predictions))\n",
    "        fp = np.sum(np.logical_not(self._truth) * self._predictions)\n",
    "        fn = np.sum(self._truth * np.logical_not(self._predictions))\n",
    "        return (tp + tn) / (tp + tn + fp + fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n",
      "0.4\n"
     ]
    }
   ],
   "source": [
    "# Test the Metric class\n",
    "params = {\n",
    "    'truth': np.array([1,1,0,1,1,1,0,0,0,1]),\n",
    "    'predictions': np.array([1,1,1,1,0,0,1,1,0,0]),\n",
    "}\n",
    "\n",
    "print(Precision(**params)())\n",
    "print(Recall(**params)())\n",
    "print(Accuracy(**params)())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative implementation of the Metric class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric():\n",
    "    \"\"\"\n",
    "    This is the base class for all the metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, truth, predictions, **kwargs):\n",
    "        \"\"\"\n",
    "        Class constructor\n",
    "        \n",
    "        :param truth: numpy array with the true values.\n",
    "        :param predictions: numpy array with the predictions.\n",
    "            The shape must be equal to truths's.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Check that truth and predictions have the same shape\n",
    "        if truth.shape != predictions.shape:\n",
    "            raise ValueError(\n",
    "                'The shape of truth ({}) and the one of the predictions ({}) differ'.format(\n",
    "                    truth.shape,\n",
    "                    predictions.shape,\n",
    "                ))\n",
    "        \n",
    "        # Store the truth and predictions in private members\n",
    "        self._truth = truth\n",
    "        self._predictions = predictions\n",
    "\n",
    "        # Store the rest of the kwargs in a separate private member\n",
    "        self._additionals = kwargs\n",
    "        \n",
    "        # Calculate the true positives and store them in a private member\n",
    "        # This is done only with true positives because they're used in all metrics\n",
    "        self._tp = np.sum(self._truth * self._predictions)\n",
    "        \n",
    "        # Initialize the rest of the intermediate results with None\n",
    "        self._tn = None\n",
    "        self._fp = None\n",
    "        self._fn = None\n",
    "        \n",
    "        \n",
    "    def precision(self):\n",
    "        \"\"\"\n",
    "        This method calculates and returns the precision\n",
    "        \"\"\"\n",
    "\n",
    "        # Update intermediate values if required and return the precision\n",
    "        if self._fp is None:\n",
    "            self._fp = np.sum(np.logical_not(self._truth) * self._predictions)\n",
    "        return self._tp / (self._tp + self._fp)\n",
    "\n",
    "\n",
    "    def recall(self):\n",
    "        \"\"\"\n",
    "        This method calculates and returns the recall\n",
    "        \"\"\"\n",
    "\n",
    "        # Update intermediate values if required and return the precision\n",
    "        if self._fn is None:\n",
    "            self._fn = np.sum(self._truth * np.logical_not(self._predictions))\n",
    "        return self._tp / (self._tp + self._fn)\n",
    "\n",
    "    \n",
    "    def accuracy(self):\n",
    "        \"\"\"\n",
    "        This method calculates and returns the accuracy\n",
    "        \"\"\"\n",
    "\n",
    "        # Update intermediate values if required and return the accuracy\n",
    "        if self._tn is None:\n",
    "            self._tn = np.sum(np.logical_not(self._truth) * np.logical_not(self._predictions))\n",
    "        if self._fp is None:\n",
    "            print('kasudhcbikasdubbc')\n",
    "            self._fp = np.sum(np.logical_not(self._truth) * self._predictions)\n",
    "        if self._fn is None:\n",
    "            print('laidfosdifuvbks')\n",
    "            self._fn = np.sum(self._truth * np.logical_not(self._predictions))\n",
    "        return (self._tp + self._tn) / (self._tp + self._tn + self._fp + self._fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n",
      "0.4\n"
     ]
    }
   ],
   "source": [
    "# Test the Metric class\n",
    "metric = Metric(np.array([1,1,0,1,1,1,0,0,0,1]), np.array([1,1,1,1,0,0,1,1,0,0]))\n",
    "\n",
    "print(metric.precision())\n",
    "print(metric.recall())\n",
    "print(metric.accuracy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio #10:   Dataset a NumPy Estructurado - Patrón de Diseño Singleton\n",
    "Para este ejercicio vamos a descargar un dataset de Kaggle. Es recomendable que se creen una cuenta porque es un lugar de donde potencialmente vamos a descargar muchos recursos.\n",
    "\n",
    "Pueden descargar el dataset desde [aquí](https://www.kaggle.com/rounakbanik/the-movies-dataset/data?select=ratings.csv).\n",
    "\n",
    "El objetivo del ejercicio es crear una clase que permita realizar las siguientes funciones sobre el dataset:\n",
    "* Crear la estructura de un structured numpy array para el dataset.\n",
    "* Leer el csv, almacenar la información en el array estructurado.\n",
    "* Guardar el array estructurado en formato .pkl.\n",
    "* Crear una instancia singleton del array estructurado (utilizando \\_\\_new__ e \\_\\_init__).\n",
    "* Al crear la instancia, si se encuentra el .pkl cargar desde el pkl. Si el .pkl no está, comenzar por transformar el .csv en .pkl y luego levantar la información.\n",
    "* Encontrar una forma de optimizar la operación usando generators [opcional].\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import zipfile\n",
    "import os\n",
    "import csv\n",
    "import pickle as pkl\n",
    "\n",
    "\n",
    "def get_data(file_path):\n",
    "    \"\"\"\n",
    "    Generator for loading a csv row by row\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the generator\n",
    "    with open(file_path, 'r') as opened_file:\n",
    "        reader = csv.reader(opened_file, delimiter=',')\n",
    "        for i, row in enumerate(reader):\n",
    "            if i == 0:\n",
    "                # Skip first line with headers\n",
    "                continue\n",
    "            yield tuple(row)\n",
    "\n",
    "\n",
    "class Dataset():\n",
    "    \"\"\"\n",
    "    This class holds a dataset as a singleton\n",
    "    \"\"\"\n",
    "    # Initialize the instance with None\n",
    "    instance = None\n",
    "    \n",
    "    \n",
    "    def __new__(cls, folder_path, zip_file_name):\n",
    "        \"\"\"\n",
    "        Return the instance of the dataset. Define it if needed.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Return the instance if it already exists\n",
    "        if cls.instance is not None:\n",
    "            return cls.instance\n",
    "                \n",
    "        # Load the instance from the pickle if available\n",
    "        pickle_path = os.path.join(folder_path, 'data.pkl')\n",
    "        if os.path.isfile(pickle_path):\n",
    "            with open(pickle_path, 'rb') as pkl_file:\n",
    "                cls.instance = pkl.load(pkl_file)\n",
    "            return cls.instance            \n",
    "                \n",
    "        # Generate the instance\n",
    "        csv_path = os.path.join(folder_path, zip_file_name)\n",
    "        with tempfile.TemporaryDirectory() as temporary_dir:\n",
    "            # Unzip the csv in a temporary folder\n",
    "            with zipfile.ZipFile(csv_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(temporary_dir)\n",
    "                \n",
    "            # Load the structured array using a generator\n",
    "            dtypes = [\n",
    "                ('userId', np.uint32),\n",
    "                ('movieId', np.uint32),\n",
    "                ('rating', np.float32),\n",
    "                ('timestamp', np.uint32),\n",
    "            ]\n",
    "            file_path = os.path.join(temporary_dir, 'ratings.csv')\n",
    "            cls.instance = np.fromiter(get_data(file_path), dtype=dtypes)\n",
    "        \n",
    "        # Save the instance as a pickle and return it\n",
    "        with open(pickle_path, 'wb') as pkl_file:\n",
    "            pkl.dump(cls.instance, pkl_file)\n",
    "        return cls.instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the previous implementation\n",
    "folder_path = '/home/rodolfo/Desktop/especializacion/IA'\n",
    "zip_file_name = 'movies.zip'\n",
    "ds = Dataset(folder_path, zip_file_name)\n",
    "print(ds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
