{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guía de Ejercicios\n",
    "Ejercicios de aplicación de NumPy aplicados a Ingeniería de Features y Regresión Lineal.\n",
    "\n",
    "#### Ejecicio #1:    Normalización\n",
    "Muchos algoritmos de Machine Learning necesitan datos de entrada centrados y normalizados. Una normalización habitual es el z-score, que implica restarle la media y dividir por el desvío a cada feature de mi dataset. \n",
    "\n",
    "Dado un dataset X de n muestras y m features, implementar un método en numpy para normalizar con z-score. Pueden utilizar np.mean() y np.std().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def z_score(dataset):\n",
    "    \"\"\"\n",
    "    This function returns a dataset which has the z-score if the input dataset\n",
    "    \n",
    "    :param dataset: the input dataset\n",
    "    :return: the z-score of the input dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    # Normalize and return\n",
    "    return (dataset - np.mean(dataset, axis=0)) / np.std(dataset, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.  1.  1.]\n",
      " [ 1. -1. -1.]]\n"
     ]
    }
   ],
   "source": [
    "# Test the previous function\n",
    "\n",
    "dataset = np.array([[0, 10, 100], [1, 2, 3]])\n",
    "print(z_score(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Ejecicio #2:    Remover filas y columnas con NaNs en un dataset\n",
    "Dado un dataset, hacer una función que, utilizando numpy, filtre las columnas y las filas que tienen NaNs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_nan(dataset, rows=True):\n",
    "    \"\"\"\n",
    "    This function removes the rows (or columns) which contain NaNs\n",
    "    \n",
    "    :param dataset: the dataset which has to be cleaned up\n",
    "    :param rows: if True, rows are removed. Otherwise, columns are removed\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the coordinates of the NaNs\n",
    "    coords = np.where(np.isnan(dataset))\n",
    "    \n",
    "    # Remove the rows or columns\n",
    "    if rows:\n",
    "        # Get the indexes of the rows which contain NaNs\n",
    "        indexes = coords[:][0]\n",
    "        return np.delete(dataset, np.unique(indexes), axis=0)\n",
    "    indexes = coords[:][1]\n",
    "    return np.delete(dataset, np.unique(indexes), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 3.]]\n",
      "[[ 0. 10.]\n",
      " [ 1.  2.]\n",
      " [ 3.  2.]]\n"
     ]
    }
   ],
   "source": [
    "# Test the previous function\n",
    "\n",
    "dataset = np.array([[0, 10, np.nan], [1, 2, 3], [3, 2, np.nan]])\n",
    "print(filter_nan(dataset, rows=True))\n",
    "print(filter_nan(dataset, rows=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejecicio #3:    Reemplazar NaNs por la media de la columna\n",
    "Dado un dataset, hacer una función que utilizando numpy reemplace los NaNs por la media de la columna.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_by_mean(dataset):\n",
    "    \"\"\"\n",
    "    This function replaces the NaNs by the mean of the column\n",
    "    \n",
    "    :param dataset: the dataset which has to be cleaned up\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the coordinates of the NaNs and replace by the column means\n",
    "    means = np.nanmean(dataset, axis=0)\n",
    "    coords = np.where(np.isnan(dataset))\n",
    "    for x, y in coords:\n",
    "        dataset[x][y] = means[y]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. 10.  3.]\n",
      " [ 1.  2.  3.]\n",
      " [ 3.  2.  3.]]\n"
     ]
    }
   ],
   "source": [
    "# Test the previous function\n",
    "\n",
    "dataset = np.array([[0, 10, np.nan], [1, 2, 3], [3, 2, np.nan]])\n",
    "print(nan_by_mean(dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejecicio #4:    Dado un dataset X separarlo en 70 / 20 / 10\n",
    "Como vimos en el ejercicio integrador, en problemas de Machine Learning es fundamental que separemos los datasets de n muestras, en 3 datasets de la siguiente manera:\n",
    "\n",
    "* Training dataset: los datos que utilizaremos para entrenar nuestros modelos. Ej: 70% de las muestras.\n",
    "* Validation dataset: los datos que usamos para calcular métricas y ajustar los hiperparámetros de nuestros modelos. Ej: 20% de las muestras.\n",
    "* Testing dataset: una vez que entrenamos los modelos y encontramos los hiperparámetros óptimos de los mísmos, el testing dataset se lo utiliza para computar las métricas finales de nuestros modelos y analizar cómo se comporta respecto a la generalización. Ej: 10% de las muestras.\n",
    "\n",
    "A partir de utilizar np.random.permutation, hacer un método que dado un dataset, devuelva los 3 datasets como nuevos numpy arrays.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, train=70, validate=20):\n",
    "    \"\"\"\n",
    "    This function splits a dataset into training, validation and testing\n",
    "    \n",
    "    :param dataset: the dataset to be split\n",
    "    :param train: the percentage of the samples to be used for training, expressed as percentage\n",
    "    :param validate: the percentage of the samples to be used for validation, expressed as percentage.\n",
    "        The remaining of training and validation is used for testing\n",
    "    :return:\n",
    "        - Training set\n",
    "        - Validation set\n",
    "        - Testing set (might be empty)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate input and calculate testing percentage\n",
    "    if train >= 100:\n",
    "        return None\n",
    "    if train + validate > 100:\n",
    "        validate = 100 - train\n",
    "    test = 100 - train - validate\n",
    "    \n",
    "    # Get the indexes for splitting the dataset\n",
    "    n_elements = dataset.shape[0]\n",
    "    train_lim = int(n_elements * train / 100)\n",
    "    validate_lim = int(n_elements * (train + validate) / 100)\n",
    "    \n",
    "    # Permutate and split the dataset and return it\n",
    "    dataset = np.random.permutation(dataset)\n",
    "    return(dataset[:train_lim], dataset[train_lim:validate_lim], dataset[validate_lim:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[3, 2],\n",
      "       [3, 2],\n",
      "       [1, 2],\n",
      "       [3, 2],\n",
      "       [1, 2],\n",
      "       [1, 2],\n",
      "       [3, 2]]), array([[1, 2],\n",
      "       [1, 2]]), array([[ 0, 10]]))\n"
     ]
    }
   ],
   "source": [
    "# Test the previous function\n",
    "\n",
    "dataset = np.array([[0, 10], [1, 2], [3, 2], [1, 2], [3, 2], [1, 2], [3, 2], [1, 2], [3, 2], [1, 2]])\n",
    "print(split_dataset(dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio #5:   A partir del dataset de consigna, aplicar los conceptos de regresión lineal.\n",
    "1. Armar una clase para cargar el [dataset](data/income.csv) en un ndarray estructurado, tal como se realizó en el ejercicio 10 de la Clase 1.\n",
    "2. Incluir un método split a la clase para obtener los sets de training y test.\n",
    "3. Crear una clase métrica base y una clase MSE (Error cuadrático medio) que herede de la clase base.\n",
    "4. Crear una clase modelo base y clases regresión lineal y regresión afín que hereden de la primera. Usar los conocimientos teóricos vistos en clase.\n",
    "5. Hacer un fit de las regresiones con los datos de entrenamiento.\n",
    "6. Hacer un predict sobre los datos de test y reportar el MSE en cada caso.\n",
    "7. Graficar la curva obtenida.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 y 2\n",
    "\n",
    "import tempfile\n",
    "import zipfile\n",
    "import os\n",
    "import csv\n",
    "import pickle as pkl\n",
    "\n",
    "\n",
    "def get_data(file_path):\n",
    "    \"\"\"\n",
    "    Generator for loading a csv row by row\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the generator\n",
    "    with open(file_path, 'r') as opened_file:\n",
    "        reader = csv.reader(opened_file, delimiter=',')\n",
    "        for i, row in enumerate(reader):\n",
    "            if i == 0:\n",
    "                # Skip first line with headers\n",
    "                continue\n",
    "            yield tuple(row)\n",
    "\n",
    "\n",
    "class Dataset():\n",
    "    \"\"\"\n",
    "    This class holds a dataset as a singleton\n",
    "    \"\"\"\n",
    "    # Initialize the instance with None\n",
    "    instance = None\n",
    "    \n",
    "    \n",
    "    def __new__(cls, folder_path, file_name):\n",
    "        if Dataset.instance is None:\n",
    "            Dataset.instance = super(Dataset, cls).__new__(cls)\n",
    "            return Dataset.instance\n",
    "        else:\n",
    "            return Dataset.instance\n",
    "    \n",
    "    \n",
    "    def __init__(self, folder_path, file_name):\n",
    "        \"\"\"\n",
    "        Class constructor. Loads dataset into self.data\n",
    "        \"\"\"\n",
    "        \n",
    "        # Load the instance from the pickle if available\n",
    "        pickle_path = os.path.join(folder_path, 'data.pkl')\n",
    "        if os.path.isfile(pickle_path):\n",
    "            with open(pickle_path, 'rb') as pkl_file:\n",
    "                self.data = pkl.load(pkl_file)\n",
    "            return\n",
    "                \n",
    "        # Generate the instance and load the structured array using a generator\n",
    "        csv_path = os.path.join(folder_path, file_name)\n",
    "        dtypes = [\n",
    "            ('id', np.uint32),\n",
    "            ('income', np.float32),\n",
    "            ('happiness', np.float32),\n",
    "        ]\n",
    "        self.data = np.fromiter(get_data(csv_path), dtype=dtypes)\n",
    "        \n",
    "        # Save the data as a pickle\n",
    "        with open(pickle_path, 'wb') as pkl_file:\n",
    "            pkl.dump(self.data, pkl_file)\n",
    "\n",
    "            \n",
    "    def split(self, train=70, validate=20):\n",
    "        \"\"\"\n",
    "        Wrapper of the split_dataset method\n",
    "        \"\"\"\n",
    "        \n",
    "        return split_dataset(self.data, train, validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([(306, 2.3071978, 3.5096047 ), (191, 6.6280365, 4.402663  ),\n",
      "       (474, 1.5873153, 1.3127589 ), (254, 6.4607425, 3.4269116 ),\n",
      "       (448, 2.8684187, 1.7917535 ), (377, 4.381923 , 3.550337  ),\n",
      "       ( 27, 3.90041  , 3.5652244 ), (422, 6.635954 , 4.7600145 ),\n",
      "       (101, 6.5012746, 4.374832  ), ( 80, 5.3374605, 3.703438  ),\n",
      "       ( 41, 5.061758 , 3.3580716 ), (104, 4.748859 , 4.902992  ),\n",
      "       (384, 4.851314 , 3.8355777 ), (482, 7.225192 , 4.985255  ),\n",
      "       (495, 3.4717987, 2.5350022 ), (397, 5.49259  , 4.1052246 ),\n",
      "       (369, 6.392483 , 3.6963904 ), (420, 6.475625 , 5.368041  ),\n",
      "       (235, 2.0705624, 0.6289421 ), (195, 3.670377 , 3.476499  ),\n",
      "       (320, 2.8090909, 2.9468703 ), (289, 5.644714 , 3.7543013 ),\n",
      "       (252, 3.5405042, 3.552737  ), (187, 6.633619 , 5.38007   ),\n",
      "       (  5, 7.196409 , 5.5963984 ), (316, 4.420312 , 4.391593  ),\n",
      "       (411, 4.087462 , 3.2178473 ), (446, 2.220404 , 0.68890923),\n",
      "       ( 61, 6.9560795, 5.498147  ), ( 96, 5.9322696, 3.9662154 ),\n",
      "       (429, 3.860696 , 2.4350948 ), (186, 5.6884875, 4.658743  ),\n",
      "       (136, 5.6346436, 4.8081503 ), (455, 5.9191294, 4.3782597 ),\n",
      "       (282, 6.707825 , 4.810424  ), (354, 4.2800756, 3.640884  ),\n",
      "       ( 91, 4.0025373, 1.7759326 ), (220, 7.46351  , 4.503445  ),\n",
      "       (436, 5.754941 , 3.9801953 ), (424, 7.0320573, 5.0401745 ),\n",
      "       (208, 7.1367598, 5.5066214 ), ( 32, 1.8556452, 1.5903559 ),\n",
      "       (278, 1.9094992, 1.6276951 ), (406, 6.3201914, 4.2843056 ),\n",
      "       (376, 5.6984515, 4.035727  ), (194, 1.5736938, 0.68809056),\n",
      "       (310, 4.1595764, 1.7903423 ), (484, 2.0318177, 2.9673233 ),\n",
      "       (430, 5.6953387, 4.5532165 ), (  2, 4.9793816, 3.4334898 ),\n",
      "       (404, 6.8223767, 4.3375716 ), (293, 5.2984805, 3.5148919 ),\n",
      "       (328, 2.6940222, 2.197592  ), (438, 1.6238137, 1.416661  ),\n",
      "       (350, 2.9965208, 1.6622531 ), (298, 1.6183114, 1.5112051 ),\n",
      "       (177, 1.5763657, 0.9876032 ), (375, 2.5174637, 1.5295609 ),\n",
      "       (122, 6.1175303, 4.691999  ), (217, 2.0851305, 2.7403953 ),\n",
      "       ( 86, 7.1861124, 5.1515985 ), (174, 4.1765323, 3.0207245 ),\n",
      "       ( 89, 3.2339425, 2.3995614 ), (  1, 3.8626475, 2.314489  ),\n",
      "       (118, 4.932207 , 4.933044  ), (149, 3.7350175, 2.8412387 ),\n",
      "       (394, 5.741725 , 3.7764847 ), (367, 6.0891623, 5.2752943 ),\n",
      "       ( 56, 6.5102186, 4.0045376 ), (453, 6.0045214, 4.93241   ),\n",
      "       (299, 6.6876774, 5.5228915 ), (341, 4.483586 , 3.031497  ),\n",
      "       (472, 7.2977223, 6.3842745 ), ( 22, 3.528319 , 2.5465245 ),\n",
      "       (362, 3.8810987, 3.1563675 ), (490, 6.0523815, 4.633441  ),\n",
      "       ( 48, 5.2411895, 3.5432036 ), (412, 3.3145561, 2.2204704 ),\n",
      "       (263, 5.099417 , 4.737046  ), (198, 2.1423595, 0.97133243),\n",
      "       (165, 5.5299087, 3.8221796 ), (401, 7.4238324, 4.9096885 ),\n",
      "       (396, 6.195004 , 4.0583115 ), (162, 6.030607 , 4.8218102 ),\n",
      "       (242, 5.0148096, 3.3137965 ), (357, 2.1699774, 1.8533477 ),\n",
      "       (486, 6.101565 , 3.9617295 ), (193, 4.6959634, 2.7842445 ),\n",
      "       (212, 2.8139   , 1.7596986 ), (312, 3.3838966, 0.7316363 ),\n",
      "       (334, 2.0484977, 2.575055  ), (126, 5.952002 , 3.5647237 ),\n",
      "       (458, 5.7208776, 3.5963984 ), (180, 5.189031 , 4.767596  ),\n",
      "       (204, 3.0399418, 4.0838213 ), (189, 3.897738 , 2.7997475 ),\n",
      "       ( 52, 5.370337 , 3.2251327 ), (460, 1.6116064, 3.4811378 ),\n",
      "       (139, 4.4176655, 3.4685738 ), (  9, 3.1216304, 2.9424498 ),\n",
      "       (144, 3.4100304, 2.0890424 ), (116, 4.3170323, 3.6616564 ),\n",
      "       (228, 7.300903 , 6.0049872 ), ( 51, 2.2533991, 1.5584226 ),\n",
      "       (442, 1.6606505, 0.69846   ), (355, 1.8244557, 0.26604366),\n",
      "       (236, 5.22407  , 3.3441083 ), (426, 3.044114 , 1.8719579 ),\n",
      "       (478, 6.4499454, 3.4923103 ), (286, 4.2782097, 3.691348  ),\n",
      "       (414, 5.405749 , 4.8530326 ), (224, 6.3773766, 5.079476  ),\n",
      "       (432, 2.0990934, 1.4787872 ), (296, 5.0956154, 5.63846   ),\n",
      "       (233, 2.9227064, 1.9195111 ), (166, 2.4093816, 1.8575419 ),\n",
      "       (451, 3.4371648, 3.8029706 ), (336, 6.919943 , 6.236955  ),\n",
      "       (211, 7.4784465, 4.8777256 ), ( 26, 6.691993 , 5.381479  ),\n",
      "       (277, 3.8201153, 2.2467458 ), ( 68, 1.6804739, 1.6060723 ),\n",
      "       (440, 7.4815216, 6.1962957 ), (113, 4.606176 , 1.9993255 ),\n",
      "       (137, 5.461636 , 4.017611  ), ( 16, 2.5591657, 2.8985832 ),\n",
      "       (178, 1.9241337, 1.4611444 ), (439, 5.9063587, 4.3284173 ),\n",
      "       (145, 3.5810971, 1.8436757 ), (109, 3.0976157, 1.6723906 ),\n",
      "       (476, 5.723226 , 4.425995  ), (260, 3.8272545, 2.3216977 ),\n",
      "       ( 23, 2.4287517, 1.2007855 ), ( 13, 7.1194787, 5.951814  ),\n",
      "       (105, 5.459161 , 4.8335066 ), (459, 3.3999164, 3.261182  ),\n",
      "       (219, 5.074502 , 3.9410193 ), (491, 3.1540425, 1.2941365 ),\n",
      "       (253, 3.1398258, 1.245786  ), (419, 7.0255175, 4.8115335 ),\n",
      "       ( 74, 2.8646638, 4.1596093 ), (  3, 4.923957 , 4.5993733 ),\n",
      "       (229, 3.0372317, 2.4106355 ), ( 54, 5.482862 , 3.8574243 ),\n",
      "       (175, 3.7480931, 3.7491808 ), (218, 4.5895724, 4.250568  ),\n",
      "       (179, 5.904246 , 4.5768566 ), (403, 5.712587 , 5.7437363 ),\n",
      "       ( 43, 3.0650587, 3.40798   ), (364, 6.2672606, 5.085523  ),\n",
      "       ( 29, 2.3805127, 2.1691613 ), (342, 2.0799553, 2.847817  ),\n",
      "       (363, 3.7845604, 1.690458  ), (112, 3.5345662, 2.6674654 ),\n",
      "       (292, 5.845197 , 4.1598873 ), (158, 2.539089 , 1.7486511 ),\n",
      "       (274, 3.8427098, 2.46886   ), (127, 3.9223027, 2.2537215 ),\n",
      "       (200, 2.0903542, 1.8521177 ), (408, 4.699896 , 3.9904158 ),\n",
      "       (129, 6.950745 , 4.1691008 ), ( 93, 2.2806509, 0.7272212 ),\n",
      "       ( 17, 2.3547933, 1.2311676 ), (226, 7.3642135, 6.61828   ),\n",
      "       (  7, 4.674517 , 3.1929917 ), ( 76, 6.483984 , 5.068748  ),\n",
      "       (207, 2.6284828, 1.6192261 ), (290, 3.5711753, 4.2452154 ),\n",
      "       (483, 3.2753348, 2.7981608 ), (199, 3.656486 , 2.8576143 ),\n",
      "       ( 90, 1.5141532, 0.85949904), (465, 4.315794 , 3.3575974 ),\n",
      "       (159, 6.708604 , 6.064013  ), (450, 6.8357477, 5.1593313 ),\n",
      "       (317, 6.4771533, 5.3139567 ), (249, 7.153674 , 4.7209873 ),\n",
      "       (368, 6.3742537, 3.6702914 ), (435, 6.840931 , 5.9157815 ),\n",
      "       (371, 2.9081469, 2.3635647 ), (210, 1.5586567, 0.9685273 ),\n",
      "       (  4, 3.2143724, 2.7911139 ), (359, 2.6837313, 2.4662924 ),\n",
      "       (271, 3.8598924, 2.719432  ), (196, 7.194407 , 5.8361964 ),\n",
      "       (216, 5.470125 , 4.66029   ), (243, 2.6020372, 2.1526985 ),\n",
      "       ( 42, 3.98219  , 2.4000874 ), (239, 7.20706  , 4.2094707 ),\n",
      "       (167, 4.2647896, 3.7510893 ), (234, 4.427109 , 3.581381  ),\n",
      "       (380, 5.4564414, 3.1354752 ), ( 94, 2.1898656, 0.77128655),\n",
      "       (183, 3.2213936, 3.4531028 ), (140, 5.760289 , 4.7587857 ),\n",
      "       (250, 2.2898974, 1.5719498 ), (473, 5.8734937, 3.2674754 ),\n",
      "       (372, 2.349952 , 1.4385961 ), (302, 5.1960826, 3.3176067 ),\n",
      "       (488, 4.2438726, 4.7541685 ), (276, 3.4005969, 0.6869208 ),\n",
      "       (134, 4.8673396, 3.7399957 ), ( 57, 6.029214 , 4.8020916 ),\n",
      "       ( 83, 3.520255 , 3.5838752 ), (496, 6.08761  , 4.3974514 ),\n",
      "       (161, 5.082658 , 3.113342  ), ( 15, 2.1177423, 1.4457989 ),\n",
      "       (270, 2.6464581, 1.7881763 ), (340, 1.6974638, 0.5461902 ),\n",
      "       ( 46, 5.3587155, 3.7526596 ), (321, 5.6862054, 3.872789  ),\n",
      "       (115, 6.879333 , 5.2114015 ), (275, 4.9905486, 3.4517725 ),\n",
      "       (173, 5.46464  , 2.7277157 ), ( 77, 4.9380364, 3.0407972 ),\n",
      "       ( 38, 7.076166 , 5.010577  ), (181, 1.8798681, 0.43817157),\n",
      "       (142, 2.1825616, 0.99291736), (402, 2.5077686, 2.1557336 ),\n",
      "       (111, 1.8283063, 1.2654889 ), ( 60, 2.7573385, 2.4806066 ),\n",
      "       (221, 5.8539057, 4.633229  ), ( 81, 2.8258266, 2.1889381 ),\n",
      "       (157, 2.4593215, 2.0427394 ), (324, 2.9257035, 3.7528248 ),\n",
      "       (418, 6.8969293, 5.265479  ), (272, 4.1215305, 4.2126975 ),\n",
      "       (273, 6.3859406, 4.4772716 ), (409, 7.2467546, 5.8901486 ),\n",
      "       (400, 4.6337414, 3.706661  ), (381, 1.7883599, 1.1452959 ),\n",
      "       ( 40, 1.9564861, 1.9275788 ), ( 11, 4.6328397, 3.1754062 ),\n",
      "       ( 37, 2.2431135, 0.9728829 ), (444, 2.9659917, 1.5603554 ),\n",
      "       (251, 6.376228 , 6.1869454 ), (285, 5.1285453, 3.757379  ),\n",
      "       (326, 2.6855297, 2.8211927 ), (461, 4.7836857, 3.393439  ),\n",
      "       (215, 6.562794 , 4.7958426 ), (405, 3.3675919, 2.5824165 ),\n",
      "       (182, 2.5443478, 2.3512025 ), (494, 5.249209 , 4.5687046 ),\n",
      "       (445, 6.279265 , 4.234991  ), (114, 5.361503 , 5.2318635 ),\n",
      "       (108, 5.5063953, 4.261013  ), ( 31, 6.9332957, 6.2991014 ),\n",
      "       (213, 5.7445397, 5.032211  ), (489, 5.3185754, 2.9619567 ),\n",
      "       (441, 2.6078532, 1.945961  ), (378, 4.772059 , 3.5546002 ),\n",
      "       (155, 6.34537  , 4.000819  ), (392, 4.947372 , 3.6154711 ),\n",
      "       (106, 3.4330647, 3.1722994 ), ( 88, 3.594802 , 2.968187  ),\n",
      "       (493, 3.4351017, 2.1151364 ), (153, 3.6814857, 3.03682   ),\n",
      "       (117, 3.3831637, 1.4150347 ), (255, 2.6413484, 1.8771471 ),\n",
      "       (374, 3.4835992, 2.3253093 ), (133, 4.5333953, 2.9475315 ),\n",
      "       (230, 6.7032666, 4.26122   ), (172, 6.847515 , 4.486704  ),\n",
      "       (150, 4.3932085, 2.9443913 ), (393, 1.5749537, 1.5022116 ),\n",
      "       (148, 6.271786 , 4.940228  ), (223, 7.0627923, 6.863388  ),\n",
      "       (281, 3.354252 , 2.5725982 ), (170, 5.157697 , 4.600115  ),\n",
      "       (462, 4.5914893, 4.2296634 ), (259, 6.8312573, 3.837978  ),\n",
      "       (333, 5.3246326, 3.7305698 ), (103, 2.2864954, 1.8935568 ),\n",
      "       (423, 4.604409 , 3.4158065 ), (135, 4.0560055, 3.5714464 ),\n",
      "       ( 45, 3.7894292, 2.4730794 ), ( 70, 4.043891 , 2.2082405 ),\n",
      "       ( 28, 2.2910554, 0.953413  ), (247, 2.3712304, 3.9610329 ),\n",
      "       ( 14, 7.4666533, 5.9605474 ), ( 49, 7.1016197, 5.348353  ),\n",
      "       ( 47, 5.19612  , 4.087631  ), (471, 7.1195054, 4.9819813 ),\n",
      "       ( 64, 6.1666813, 4.7196655 ), (160, 6.831322 , 5.1324015 ),\n",
      "       ( 21, 7.310916 , 5.747444  ), (176, 2.274523 , 2.3115542 ),\n",
      "       (284, 1.9311807, 2.4657612 ), (395, 5.9104753, 3.2010424 ),\n",
      "       (481, 7.448117 , 5.9634223 ), (190, 6.461243 , 4.2067547 ),\n",
      "       ( 44, 3.6828775, 2.5761764 ), (288, 2.9076822, 1.4102296 ),\n",
      "       ( 85, 3.4983864, 2.200982  ), ( 73, 1.506275 , 1.3084873 ),\n",
      "       (143, 4.2919836, 3.1693802 ), (433, 3.4989674, 2.7685232 ),\n",
      "       (467, 6.5461326, 5.5883894 ), (339, 7.3105025, 5.923346  ),\n",
      "       (192, 3.1189592, 2.769118  ), (110, 4.647556 , 1.4970242 ),\n",
      "       ( 98, 5.664345 , 3.7732606 ), (  6, 3.7296436, 2.458556  ),\n",
      "       (311, 1.5446343, 1.6446366 ), ( 72, 4.8635817, 3.5679052 ),\n",
      "       (449, 3.9281409, 3.227472  ), (315, 1.8484125, 2.097369  ),\n",
      "       (125, 2.194882 , 2.393228  ), (413, 6.7683363, 5.910285  ),\n",
      "       (201, 3.3630972, 3.5151792 ), ( 97, 5.3078394, 2.8904474 ),\n",
      "       (283, 6.3259063, 4.8274164 ), ( 92, 6.198104 , 4.661261  ),\n",
      "       (492, 2.4823816, 0.5483652 ), (225, 1.9208628, 1.6252683 ),\n",
      "       (477, 5.237893 , 3.3427494 ), (294, 3.4347   , 2.714498  ),\n",
      "       (322, 4.8003435, 2.8428683 ), (470, 6.781564 , 4.985367  ),\n",
      "       ( 20, 1.9942751, 2.584729  ), (383, 5.0809684, 3.8222039 ),\n",
      "       ( 65, 6.074158 , 4.503108  ), (287, 1.5794703, 1.9818099 ),\n",
      "       ( 58, 6.949113 , 4.6588902 ), ( 10, 4.6399145, 3.7379415 ),\n",
      "       ( 69, 5.499948 , 4.8266025 ), (209, 3.1049182, 1.0959992 ),\n",
      "       (410, 5.666951 , 3.6885395 ), (313, 3.6147451, 2.9017885 ),\n",
      "       (360, 1.6511561, 1.7235936 ), (268, 4.9758515, 4.540636  ),\n",
      "       ( 62, 4.6701927, 4.550637  ), (197, 1.7804787, 2.003926  ),\n",
      "       (309, 3.5743937, 1.4244505 ), (156, 5.9397416, 4.5708013 ),\n",
      "       ( 84, 3.2399406, 3.0968857 ), (454, 3.283167 , 2.2334406 ),\n",
      "       (497, 3.440847 , 2.0706637 ), ( 34, 6.826478 , 5.9142475 ),\n",
      "       (331, 5.0915794, 4.4569635 ), (343, 4.8343973, 4.5169606 ),\n",
      "       (373, 7.004399 , 5.362448  ), ( 95, 3.4341512, 3.3487883 ),\n",
      "       (487, 6.074328 , 4.6491437 ), (468, 4.6882195, 2.9942043 ),\n",
      "       (154, 7.241313 , 4.682817  ), (307, 2.730769 , 2.6469045 ),\n",
      "       ( 12, 2.7731788, 2.0090466 ), (280, 7.4515004, 4.109945  )],\n",
      "      dtype=[('id', '<u4'), ('income', '<f4'), ('happiness', '<f4')]), array([(417, 3.6992056, 3.2333138 ), (119, 4.9355965, 4.1307783 ),\n",
      "       ( 53, 6.225606 , 5.034231  ), (379, 5.3950167, 4.1997285 ),\n",
      "       (469, 3.126524 , 2.4133818 ), (437, 6.926721 , 4.708203  ),\n",
      "       (407, 2.2986434, 2.9621682 ), (246, 6.8596544, 4.2583117 ),\n",
      "       (237, 7.161873 , 6.1604342 ), (124, 7.11722  , 5.5625453 ),\n",
      "       (382, 3.1125927, 3.539854  ), (202, 2.4231439, 2.1005526 ),\n",
      "       (370, 3.2043164, 2.6798873 ), (456, 3.9101985, 3.4839256 ),\n",
      "       (138, 3.1861758, 1.839802  ), ( 79, 7.2282653, 5.0340037 ),\n",
      "       (232, 4.2235537, 2.2957    ), ( 78, 5.6254344, 3.8042989 ),\n",
      "       (205, 2.3732321, 1.5247823 ), ( 87, 4.7191663, 5.9509864 ),\n",
      "       (147, 6.6602163, 5.9493475 ), (264, 5.6103907, 4.5909705 ),\n",
      "       (188, 5.972741 , 3.3159895 ), ( 24, 3.542748 , 3.0782933 ),\n",
      "       (332, 6.2503023, 4.939259  ), (279, 2.8584642, 2.4532092 ),\n",
      "       (428, 5.415053 , 4.501158  ), (323, 2.4129121, 1.4606164 ),\n",
      "       (329, 4.230889 , 4.155541  ), (351, 2.8494582, 2.39155   ),\n",
      "       ( 75, 5.8779063, 4.633915  ), (130, 3.6608765, 3.8238988 ),\n",
      "       (416, 4.9249496, 3.0921648 ), (390, 5.2481756, 4.2535014 ),\n",
      "       (431, 6.3649187, 4.361709  ), (100, 2.1347022, 0.2687221 ),\n",
      "       (185, 6.481617 , 4.8200912 ), (338, 4.545707 , 3.6294243 ),\n",
      "       (398, 4.5172443, 3.7220976 ), (240, 2.184085 , 1.2262981 ),\n",
      "       (214, 6.5409884, 5.7138023 ), (480, 6.522772 , 5.3865595 ),\n",
      "       (261, 3.770671 , 3.3115783 ), (425, 3.102346 , 1.9656359 ),\n",
      "       (121, 5.7112637, 3.9011703 ), (365, 1.8903267, 2.481624  ),\n",
      "       ( 33, 3.589023 , 2.2509294 ), ( 55, 4.034172 , 3.6190555 ),\n",
      "       (257, 6.391428 , 5.2399096 ), ( 19, 4.75568  , 2.666116  ),\n",
      "       (443, 6.235585 , 5.135455  ), (132, 3.5403411, 2.57694   ),\n",
      "       (164, 3.574297 , 1.6312611 ), (347, 4.255557 , 3.6188297 ),\n",
      "       (479, 4.1723366, 3.7512255 ), (345, 4.2700367, 3.1577652 ),\n",
      "       (327, 2.1244292, 2.73496   ), ( 36, 5.2242055, 5.767814  ),\n",
      "       (120, 2.6015532, 2.2822669 ), (227, 6.535799 , 4.6569986 ),\n",
      "       (353, 3.4415133, 2.0175135 ), (356, 2.889242 , 1.2954273 ),\n",
      "       (258, 2.7637198, 1.3840442 ), ( 59, 7.1950374, 5.231703  ),\n",
      "       (388, 2.3430755, 2.9586968 ), (131, 1.7890918, 0.45837757),\n",
      "       (434, 5.994602 , 3.9606364 ), ( 67, 1.5895747, 0.66971594),\n",
      "       (385, 6.607472 , 5.6837506 ), (303, 4.1930075, 2.7796826 ),\n",
      "       ( 50, 3.424021 , 3.0563767 ), (206, 1.9845637, 2.5795164 ),\n",
      "       (318, 6.56142  , 6.28137   ), (319, 7.1809072, 5.6079664 ),\n",
      "       (304, 2.3476875, 0.8465055 ), ( 66, 5.484719 , 5.0460815 ),\n",
      "       (267, 2.3361335, 2.336276  ), (291, 2.3451076, 1.4378767 ),\n",
      "       ( 25, 5.2272015, 4.317761  ), (485, 2.8401408, 1.2287732 ),\n",
      "       (399, 4.311786 , 3.8222704 ), (203, 7.1115837, 6.086478  ),\n",
      "       (457, 2.6420987, 2.030297  ), (348, 4.2164683, 3.2007978 ),\n",
      "       (346, 5.3797956, 4.2879996 ), (427, 6.182899 , 5.3235073 ),\n",
      "       (163, 6.574595 , 4.179521  ), (447, 2.0709503, 0.6858489 ),\n",
      "       (245, 6.244342 , 3.4520671 ), (141, 3.7167003, 2.3916776 ),\n",
      "       (464, 6.0527315, 4.400455  ), (366, 1.7620581, 1.3533174 ),\n",
      "       (168, 3.5303447, 3.1586187 ), (295, 1.8659953, 1.3573731 ),\n",
      "       ( 18, 2.3881571, 2.312988  ), (269, 2.6295469, 2.192745  ),\n",
      "       (297, 1.5308077, 2.4214647 ), (152, 6.2397394, 5.0978026 ),\n",
      "       (330, 5.350516 , 4.078209  ), ( 39, 4.1906724, 2.239665  )],\n",
      "      dtype=[('id', '<u4'), ('income', '<f4'), ('happiness', '<f4')]), array([(344, 4.7613444, 4.591697  ), (222, 3.76454  , 4.0308647 ),\n",
      "       (301, 5.9838457, 3.988453  ), (262, 3.159855 , 3.0573878 ),\n",
      "       ( 30, 2.5496087, 2.0607944 ), (169, 6.14315  , 4.9271326 ),\n",
      "       (151, 3.5122168, 3.0269182 ), (238, 2.2106965, 2.8612745 ),\n",
      "       ( 99, 7.4392476, 6.3596    ), (300, 7.3472457, 4.396622  ),\n",
      "       (308, 3.8825135, 2.9779167 ), (266, 5.3637295, 3.9811277 ),\n",
      "       (386, 3.126856 , 2.517401  ), (361, 4.416321 , 4.3072886 ),\n",
      "       (305, 4.7094893, 2.4579217 ), (389, 1.600033 , 1.6809971 ),\n",
      "       (248, 5.9640574, 3.4277232 ), (107, 7.1763997, 5.0299516 ),\n",
      "       (452, 5.139565 , 4.216058  ), (256, 2.0022135, 1.8178891 ),\n",
      "       (463, 5.6718397, 4.3213644 ), (498, 4.530545 , 3.710193  ),\n",
      "       ( 71, 5.005093 , 4.0564933 ), (387, 6.5627627, 4.3246603 ),\n",
      "       (335, 2.3813853, 2.1763222 ), (184, 7.260374 , 5.3813987 ),\n",
      "       (466, 6.495855 , 5.335718  ), ( 82, 5.9313664, 5.5380473 ),\n",
      "       (325, 3.1741757, 3.1266031 ), (352, 3.7449737, 3.0676095 ),\n",
      "       (241, 4.4149985, 4.793325  ), (244, 2.9170487, 2.923684  ),\n",
      "       (337, 2.3595078, 0.8987328 ), (128, 7.081589 , 4.121648  ),\n",
      "       ( 35, 2.070602 , 2.1918337 ), (  8, 4.4981036, 1.9071368 ),\n",
      "       (391, 3.0354614, 2.2603958 ), (123, 3.7714152, 3.5778008 ),\n",
      "       (415, 3.6322834, 3.8029737 ), (358, 6.9768987, 5.367236  ),\n",
      "       (231, 1.9279966, 1.0656238 ), (421, 1.6393806, 1.7987183 ),\n",
      "       (265, 1.8563718, 0.65424216), (102, 3.6511831, 2.1558433 ),\n",
      "       (146, 3.509663 , 1.6166074 ), ( 63, 6.368293 , 3.5700135 ),\n",
      "       (314, 6.5038824, 4.317133  ), (171, 4.7108474, 2.4083798 ),\n",
      "       (349, 5.693725 , 3.999703  ), (475, 6.0018067, 4.039548  )],\n",
      "      dtype=[('id', '<u4'), ('income', '<f4'), ('happiness', '<f4')]))\n"
     ]
    }
   ],
   "source": [
    "# Test the previous implementation\n",
    "folder_path = '/home/rodolfo/Desktop/especializacion/IA'\n",
    "file_name = 'income.csv'\n",
    "ds = Dataset(folder_path, file_name)\n",
    "\n",
    "print(ds.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "\n",
    "class Metric():\n",
    "    \"\"\"\n",
    "    This is the base class for all the metrics.\n",
    "    The keys 'truth' and 'predictions' are required in the kwargs.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Class constructor\n",
    "        \"\"\"\n",
    "        \n",
    "        # Define a private member which will be True if there's any issue with the input\n",
    "        self._error = False\n",
    "        \n",
    "        # Store the truth in a private member\n",
    "        # TODO it would be better to raise errors when the required keys aren't present\n",
    "        if 'truth' not in kwargs:\n",
    "            print('The key `truth` is missing from the kwargs.')\n",
    "            self._error = True\n",
    "        else:\n",
    "            self._truth = kwargs.pop('truth')\n",
    "            \n",
    "        # Store the predictions in a private member\n",
    "        # TODO it would be better to raise errors when the required keys aren't present\n",
    "        if 'predictions' not in kwargs:\n",
    "            print('The key `predictions` is missing from the kwargs.')\n",
    "            self._error = True\n",
    "        else:\n",
    "            self._predictions = kwargs.pop('predictions')\n",
    "\n",
    "        # Check that truth and predictions have the same shape\n",
    "        if self._truth.shape != self._predictions.shape:\n",
    "            print('The shape of truth ({}) and the one of the predictions ({}) differ'.format(\n",
    "                self._truth.shape,\n",
    "                self._predictions.shape,\n",
    "            ))\n",
    "            self._error = True\n",
    "            \n",
    "        # Store the rest of the kwargs in a separate private member\n",
    "        self._additionals = kwargs\n",
    "        \n",
    "        \n",
    "class MSE(Metric):\n",
    "    \"\"\"\n",
    "    Class for obtaining the Mean Squared Error\n",
    "    \"\"\"\n",
    "    \n",
    "    def __call__(self):\n",
    "        \"\"\"\n",
    "        This method calculates and returns the precision\n",
    "        \"\"\"\n",
    "\n",
    "        # If there was any issue with the input parameters, return None\n",
    "        if self._error is True:\n",
    "            return None\n",
    "        \n",
    "        # Calculate and return the MSE\n",
    "        return np.mean((self._truth - self._predictions) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the previous class\n",
    "\n",
    "truth = np.array([1, 2, 3])\n",
    "predictions = np.array([-1, 0, 1])\n",
    "\n",
    "mse = MSE(truth=truth, predictions=predictions)\n",
    "mse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "\n",
    "# Define a Base Model class\n",
    "class Model():\n",
    "    \"\"\"\n",
    "    From this class should inherit all the model classes\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        self._x = np.atleast_2d(x)\n",
    "        self._y = np.atleast_2d(y)\n",
    "        self._params = None\n",
    "        \n",
    "        \n",
    "class LinearRegression(Model):\n",
    "    def calculate(self):\n",
    "        # Calculate and return the slopes for the linear regression\n",
    "        self._params = np.linalg.inv(self._x.T.dot(self._x)).dot(self._x.T).dot(self._y).T\n",
    "        return self._params\n",
    "    \n",
    "    def predict(self, sample):\n",
    "        return np.dot(self._params, sample.T)\n",
    "    \n",
    "\n",
    "class AffineRegression(Model):\n",
    "    def calculate(self):\n",
    "        # Calculate and return the slopes and the bias for the affine regression\n",
    "        self._x = np.concatenate((self._x, np.ones((len(self._x), 1), dtype=self._x.dtype)), axis=1)\n",
    "        lr = LinearRegression(self._x, self._y)   \n",
    "        self._params = lr.calculate()\n",
    "        return self._params\n",
    "    \n",
    "    def predict(self, sample):\n",
    "        sample_biased = np.atleast_2d(np.append(sample, 1)).T\n",
    "        return np.dot(self._params, sample_biased)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear regression model:  [[-0.0182077   7.82236267]]\n",
      "linear regression prediction:  [[54.48342324]]\n",
      "affine regression model:  [[ 1.38777878e-17  1.00000000e+01 -1.00000000e+01]]\n",
      "affine regression prediction:  [[60.]]\n"
     ]
    }
   ],
   "source": [
    "# Test the previous class\n",
    "\n",
    "# Define a test\n",
    "x = np.array([[11, 0], [4, 1], [300, 2], [-15, 3], [4, 4], [-33, 5], [40, 6]])\n",
    "y = np.array([[-10, 0, 10, 20, 30, 40, 50]]).T\n",
    "\n",
    "\n",
    "lr = LinearRegression(x, y)\n",
    "print('linear regression model: ', lr.calculate())\n",
    "print('linear regression prediction: ', lr.predict(np.array([[15, 7]])))\n",
    "\n",
    "ar = AffineRegression(x, y)\n",
    "print('affine regression model: ', ar.calculate())\n",
    "print('affine regression prediction: ', ar.predict(np.array([[15, 7]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(347, 1)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot cast array data from dtype([('id', '<u4'), ('income', '<f4'), ('happiness', '<f4')]) to dtype('V12') according to the rule 'safe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-3ae0b8bff713>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAffineRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-135-2ba09b77beb1>\u001b[0m in \u001b[0;36mcalculate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-135-2ba09b77beb1>\u001b[0m in \u001b[0;36mcalculate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalculate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Calculate and return the slopes for the linear regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot cast array data from dtype([('id', '<u4'), ('income', '<f4'), ('happiness', '<f4')]) to dtype('V12') according to the rule 'safe'"
     ]
    }
   ],
   "source": [
    "# 5\n",
    "\n",
    "# Prepare the dataset\n",
    "folder_path = '/home/rodolfo/Desktop/especializacion/IA'\n",
    "file_name = 'income.csv'\n",
    "ds = Dataset(folder_path, file_name)\n",
    "train, validate, test = ds.split()\n",
    "\n",
    "# Train the model using the training set\n",
    "x_train = train[:][:-1].reshape(len(x_train), -1)\n",
    "y_train = train[:][-1]\n",
    "ar = AffineRegression(x_train, y_train)\n",
    "params = ar.calculate()\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
